# ğŸ  House Prices â€“ Advanced Regression Techniques

**Author:** Karthikeyan M  

This project predicts house prices based on various property characteristics such as area, quality, year built, and location.  
It is built using the [Kaggle: House Prices â€“ Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) dataset.

---

## ğŸš€ Project Overview
The goal is to predict the final sale price of homes using advanced regression algorithms.  
The notebook includes end-to-end processing â€” from data cleaning and feature engineering to model training, evaluation, and visualization.

---

## ğŸ“Š Dataset
**Source:** Kaggle  
**Key Features:** `MSSubClass`, `MSZoning`, `LotArea`, `OverallQual`, `YearBuilt`, `GrLivArea`, `GarageCars`, `SalePrice`  
**Target Variable:** `SalePrice`

---

## ğŸ§  Machine Learning Models Used
- Linear Regression  
- Decision Tree Regressor  
- Random Forest Regressor  
- Support Vector Regressor (SVR)

---

## âš™ï¸ Evaluation Metrics
The models were evaluated using regression and classification-style metrics:

- Mean Absolute Error (MAE)
- Mean Squared Error (MSE)
- Root Mean Squared Error (RMSE)
- RÂ² Score
- **ROCâ€“AUC Curve** (for binary threshold classification of predicted prices)

---

## ğŸ“ˆ Model Performance Summary

| Model | RÂ² Score | RMSE | AUC | Remarks |
|-------|----------:|------:|-----:|---------|
| Linear Regression | 0.8807 | 0.197 | â€” | Baseline linear model |
| Decision Tree | 0.9992 | 0.0316 | **1.000** | âš ï¸ Overfit (perfect AUC, unrealistic) |
| Random Forest | 0.9981 | 0.1544 | 0.997 | Strong performer, minor overfit |
| **SVR** | **0.9891** | **0.1154** | **0.999** | âœ… Best balanced model (excellent AUC + generalization) |

> The Decision Tree achieved perfect RÂ² and AUC = 1.000, indicating overfitting to the training data.  
> The **SVR model** achieved nearly perfect AUC (0.999) and high RÂ² (0.989), making it the **best generalizing model overall**.

---

## ğŸ§© Feature Overview
**Numerical Features:** `OverallQual`, `GrLivArea`, `GarageCars`, `GarageArea`, `TotalBsmtSF`, `1stFlrSF`, `FullBath`, `TotRmsAbvGrd`  
**Categorical Features:** `MSZoning`, `Neighborhood`, `KitchenQual`

---

## ğŸ› ï¸ Tools & Libraries
- Python 3.9+  
- Pandas | NumPy  
- Matplotlib | Seaborn  
- Scikit-learn  
- Google Colab

---

## ğŸ“Š Visualizations
- Correlation heatmaps of numerical features  
- Feature importance bar charts  
- ROCâ€“AUC curve comparison for all models  
- Distribution plots before and after preprocessing  

---

## â–¶ï¸ How to Run
1. Open `House_Prices_Advanced_Regression_Techniques.ipynb` in **Google Colab**.  
2. Upload the Kaggle dataset files (`train.csv`, `test.csv`).  
3. Run all cells sequentially.  
4. Review the printed metrics and visualizations at the end for model comparisons.

---

## ğŸ§¾ Conclusion
- **Decision Tree** â†’ Overfits (perfect RÂ² and AUC = 1.000)  
- **Random Forest** â†’ High accuracy but slightly less generalization  
- **SVR** â†’ Best overall balance (AUC = 0.999, RÂ² = 0.9891, RMSE = 0.1154)

âœ… Final Conclusion: **SVR is the best generalized model** for predicting house prices in this project.

---

## ğŸ‘¨â€ğŸ’» Author
**Karthikeyan M**

---
